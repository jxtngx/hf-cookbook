{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5f8cc6",
   "metadata": {},
   "source": [
    "# RAG on Hugging Face Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769d66e",
   "metadata": {},
   "source": [
    "This demo shows how to perform Retrieval Augmented Generation (RAG) on documents contained in a Hugging Face Collection, and explains concepts of RAG - like vector search, reranking, and evaluating both the retrieval and generation phases of a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d1f9e-4ec2-4b43-be76-9a70b226af98",
   "metadata": {},
   "source": [
    "We will use the following tools:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa8f59",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>requirement</th>\n",
    "            <th>purpose</th>\n",
    "            <th>link</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>LangChain</td>\n",
    "            <td>LLM workflow framework</td>\n",
    "            <td><a href=\"https://python.langchain.com/v0.2/docs/introduction/\">docs</a></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Comet LLM</td>\n",
    "            <td>tracking LLM workflows</td>\n",
    "            <td><a href=\"https://www.comet.com/docs/v2/guides/comet-llm/quickstart/\">docs</a></td> \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Unstructured</td>\n",
    "            <td>document processing</td>\n",
    "            <td><a href=\"https://docs.unstructured.io/welcome\">docs</a></td> \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Llama 3 70B Instruct</td>\n",
    "            <td>synthesizer model</td>\n",
    "            <td><a href=\"https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct\">docs</a></td> \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Hugging Face Hub API</td>\n",
    "            <td>interact with the HF Hub</td>\n",
    "            <td><a href=\"https://huggingface.co/docs/huggingface_hub/index\">docs</a></td> \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Hugging Face Inference API</td>\n",
    "            <td>serverless inference for testing</td>\n",
    "            <td><a href=\"https://huggingface.co/docs/api-inference/index\">docs</a></td> \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Weaviate</td>\n",
    "            <td>vector database</td>\n",
    "            <td><a href=\"https://huggingface.co/docs/api-inference/index\">docs</a></td> \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Requests</td>\n",
    "            <td>HTTP library</td>\n",
    "            <td><a href=\"https://requests.readthedocs.io/en/latest/\">docs</a></td> \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>python-dotenv</td>\n",
    "            <td>reading environment variables</td>\n",
    "            <td><a href=\"https://saurabh-kumar.com/python-dotenv/\">docs</a></td> \n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24367ec",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad87911",
   "metadata": {},
   "source": [
    "We need to do the following:\n",
    "\n",
    "<ol>\n",
    "  <li>Create the <a href=\"https://huggingface.co/docs/hub/collections\">collection</a> on Hugging Face</li>\n",
    "  <li>Fetch the collection with the Hugging Face Hub API</li>\n",
    "  <li>Preprocess the documents contained in the collection with Unstructured</li>\n",
    "  <li>Use Weaviate and LangChain to create a vector store and retriever</li>\n",
    "  <li>Use Hugging Face's Inference API to synthesize an answer using Meta's Llama 3 70B Instruct</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec64f4",
   "metadata": {},
   "source": [
    "# Breaking down RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfe4ba",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8ba77",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094f494",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773160e0",
   "metadata": {},
   "source": [
    "### Vector search with Hierarchical Navigable Small Worlds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e1653",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3745d",
   "metadata": {},
   "source": [
    "### Embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac843d4",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948b502",
   "metadata": {},
   "source": [
    "### Reranking models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6190a3d",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702effe9",
   "metadata": {},
   "source": [
    "## Synthesis aka Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407416b",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64864eee",
   "metadata": {},
   "source": [
    "# Combining LangChain and Comet LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc62b7",
   "metadata": {},
   "source": [
    "See the Comet LLM [docs](https://www.comet.com/docs/v2/guides/comet-llm/integrations/langchain/) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de4ee9",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a820f",
   "metadata": {},
   "source": [
    "## What is LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991484b9",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156ba51",
   "metadata": {},
   "source": [
    "## What is Comet LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d654b",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da967426",
   "metadata": {},
   "source": [
    "# The Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fc4f0",
   "metadata": {},
   "source": [
    "## Get the collection and download the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33435db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import get_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46bfb7c",
   "metadata": {},
   "source": [
    "ask for a cache directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b01a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = input(\"please set a cache directory for the data. leave blank for current working directory.\")\n",
    "\n",
    "if cache_dir == \"\": \n",
    "    cache_dir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8a1c8",
   "metadata": {},
   "source": [
    "ensure the data directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join(cache_dir, \"data\")\n",
    "\n",
    "if not os.path.isdir(datadir):\n",
    "    os.mkdir(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b3858",
   "metadata": {},
   "source": [
    "get the collection's files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a283474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data dir contents\n",
    "data = os.listdir(datadir)\n",
    "# get tool use paper collection\n",
    "collection = get_collection(\"jxtngx/tool-use-papers-664c6cd9cc9c64354af51e86\")\n",
    "# make arxiv urls\n",
    "urls = [\"https://arxiv.org/pdf/\" + c.item_id for c in collection.items]\n",
    "\n",
    "# download files\n",
    "for url in urls:\n",
    "    if not os.path.exists(os.path.join(datadir, url.split('/')[-1])):\n",
    "        os.system(f\"wget -O {os.path.join(datadir, url.split('/')[-1])} {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b435a82",
   "metadata": {},
   "source": [
    "## Prep PDFs with Unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0a266",
   "metadata": {},
   "source": [
    "This section takes inspiration from the example in [Building RAG with Custom Unstructured Data](https://github.com/huggingface/cookbook/blob/main/notebooks/en/rag_with_unstructured_data.ipynb), by Maria Khalusova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0c69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "792eb455",
   "metadata": {},
   "source": [
    "## Create the vector store and retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cee8ed",
   "metadata": {},
   "source": [
    "See the [LangChain docs](https://python.langchain.com/v0.2/docs/integrations/text_embedding/huggingfacehub/) for more on the Hugging Face embeddings integration.\n",
    "\n",
    "See the [LangChain docs](https://python.langchain.com/v0.1/docs/integrations/vectorstores/weaviate/) for more on the Weaviate integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa554c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96153858",
   "metadata": {},
   "source": [
    "## Evaluate the retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5097d",
   "metadata": {},
   "source": [
    "See the [LangChain docs](https://docs.smith.langchain.com/how_to_guides/evaluation/evaluate_on_intermediate_steps) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdb846",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3013b",
   "metadata": {},
   "source": [
    "<ol>\n",
    "  <li>MMR</li>\n",
    "  <li>Hit rate</li>\n",
    "  <li>Reranking relevancy (if it exists in LangChain)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f77edb",
   "metadata": {},
   "source": [
    "## Using Hugging Face Inference Endpoints for prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b27a9d",
   "metadata": {},
   "source": [
    "See the [Hugging Face docs](huggingface.co/docs/api-inference/en/index) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e89981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eee28a1b",
   "metadata": {},
   "source": [
    "## Evaluate the synthesized output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bedfb",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38140e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
